{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mrandom\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msquigglepy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msq\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msquigglepy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m bayes\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import squigglepy as sq\n",
    "from squigglepy import bayes\n",
    "from squigglepy.numbers import K, M, B, T\n",
    "\n",
    "from copy import copy, deepcopy\n",
    "from scipy import stats\n",
    "from pprint import pprint\n",
    "from datetime import datetime as dt\n",
    "print('Loaded 1')\n",
    "\n",
    "exec(open('utils.py').read())\n",
    "print('Loaded 2')\n",
    "\n",
    "exec(open('modules/tai_timelines.py').read())\n",
    "print('Loaded TAI timelines module')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables - probably don't want to change these but you could.\n",
    "RUNS = 10000                                      # Number of runs to do (default 10000)\n",
    "MAX_YEAR = CURRENT_YEAR + 100                     # What year to end the run on?\n",
    "years = list(range(CURRENT_YEAR, MAX_YEAR))       # CURRENT_YEAR defined in utils.py\n",
    "VARIABLE_SETS = {}\n",
    "\n",
    "\n",
    "VARIABLE_SETS['Cotra2020'] = {\n",
    "    'initial_gdp': 24*T,                  # GDP in `CURRENT_YEAR` of country that will develop TAI (default: 24 trillion)\n",
    "    'algo_doubling_rate_max': 3.5,        # 90% CI, algorithms get twice as efficient every X years (maximum)\n",
    "    'algo_doubling_rate_min': 2,          # 90% CI, algorithms get twice as efficient every X years (minimum)\n",
    "    'min_reduction': 2,                   # 90% CI, the minimum amount of OOMs of reduction in TAI size algorithm improvements could acheive\n",
    "    'max_reduction': 5,                   # 90% CI, the maximum amount of OOMs of reduction in TAI size algorithm improvements could acheive\n",
    "    'initial_flop_per_dollar': 17.6,      # 90% CI, as of today, we can buy 10^X FLOP per $\n",
    "    'flop_halving_rate': 2.5,             # 90% CI, the cost of FLOP per $ halves every X years\n",
    "    'max_flop_per_dollar': 24,            # 90% CI, the cheapest FLOP will get is 10^X FLOPs per $\n",
    "    'initial_pay': 9,                     # 90% CI, as of today the maximum we would pay for TAI is $10^X\n",
    "    'gdp_growth': 1.03,                   # 90% CI, GDP will increase by a factor of X each year\n",
    "    'max_gdp_frac': 0.01,                 # 90% CI, the maximum % of GDP that would be spent on TAI is $10^X\n",
    "    'spend_doubling_time': 2.5            # 90% CI, our willingness to spend on TAI doubles every X years\n",
    "}\n",
    "\n",
    "\n",
    "VARIABLE_SETS['Cotra2022'] = deepcopy(VARIABLE_SETS['Cotra2020'])\n",
    "VARIABLE_SETS['Cotra2022']['initial_flop_per_dollar'] = 18.57\n",
    "print('Loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cotra_2020_tai_flop_size = sq.sample(load_cache_file='caches/cotra_2020')  # Cache generated in \"Anchors\" notebook\n",
    "print('Cache from: {}'.format(dt.fromtimestamp(os.path.getmtime('caches/cotra_2020.sqcache.npy'))))\n",
    "\n",
    "cotra_2020_tai_flop_size = [round(t, 1) for t in cotra_2020_tai_flop_size]\n",
    "# 90% CI, it takes 10^X FLOP to run a transformative AI at inference.\n",
    "# Note: A petaflop/s-day (pfs-day) consists of performing 10^15 neural net operations per second for one day, or a total of about 10^20 operations\n",
    "VARIABLE_SETS['Cotra2020']['tai_flop_size'] = cotra_2020_tai_flop_size\n",
    "sq.get_percentiles(cotra_2020_tai_flop_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cotra_2022_tai_flop_size = sq.sample(load_cache_file='caches/cotra_2022')  # Cache generated in \"Anchors\" notebook\n",
    "print('Cache from: {}'.format(dt.fromtimestamp(os.path.getmtime('caches/cotra_2022.sqcache.npy'))))\n",
    "cotra_2022_tai_flop_size = [round(t, 1) for t in cotra_2022_tai_flop_size]\n",
    "VARIABLE_SETS['Cotra2022']['tai_flop_size'] = cotra_2022_tai_flop_size\n",
    "sq.get_percentiles(cotra_2022_tai_flop_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Cotra 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = VARIABLE_SETS['Cotra2020']\n",
    "variables['RUNS'] = RUNS\n",
    "variables['CURRENT_YEAR'] = CURRENT_YEAR\n",
    "variables['MAX_YEAR'] = MAX_YEAR\n",
    "run_timelines_model(variables, cores=5, runs=variables['RUNS'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Cotra 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = VARIABLE_SETS['Cotra2022']\n",
    "variables['RUNS'] = RUNS\n",
    "variables['CURRENT_YEAR'] = CURRENT_YEAR\n",
    "variables['MAX_YEAR'] = MAX_YEAR\n",
    "run_timelines_model(variables, cores=5, runs=RUNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('File last ran: {}'.format(dt.now()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
